{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('TrainOnMe.csv')\n",
    "\n",
    "df = df.drop(columns=['Unnamed: 0', 'x12'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EBIT/Wh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>199.999115</td>\n",
       "      <td>0.014573</td>\n",
       "      <td>-99.948342</td>\n",
       "      <td>-1.053022</td>\n",
       "      <td>229.938275</td>\n",
       "      <td>-121.014496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013802</td>\n",
       "      <td>-0.005572</td>\n",
       "      <td>11.069748</td>\n",
       "      <td>-0.377698</td>\n",
       "      <td>950.021404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.014776</td>\n",
       "      <td>0.707570</td>\n",
       "      <td>3.169226</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>1.014779</td>\n",
       "      <td>1.795108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.209435</td>\n",
       "      <td>1.238413</td>\n",
       "      <td>2.744753</td>\n",
       "      <td>3.356351</td>\n",
       "      <td>4.986109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>196.519800</td>\n",
       "      <td>-2.546980</td>\n",
       "      <td>-112.554330</td>\n",
       "      <td>-1.070990</td>\n",
       "      <td>226.472260</td>\n",
       "      <td>-127.403190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.349350</td>\n",
       "      <td>-5.140990</td>\n",
       "      <td>0.672290</td>\n",
       "      <td>-11.232970</td>\n",
       "      <td>932.910080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>199.309460</td>\n",
       "      <td>-0.471633</td>\n",
       "      <td>-102.090328</td>\n",
       "      <td>-1.057280</td>\n",
       "      <td>229.246200</td>\n",
       "      <td>-122.232140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.707843</td>\n",
       "      <td>-0.740918</td>\n",
       "      <td>9.242318</td>\n",
       "      <td>-2.620452</td>\n",
       "      <td>946.660668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>199.990365</td>\n",
       "      <td>0.018090</td>\n",
       "      <td>-100.005840</td>\n",
       "      <td>-1.053280</td>\n",
       "      <td>229.930135</td>\n",
       "      <td>-120.996360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009350</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>11.054340</td>\n",
       "      <td>-0.591760</td>\n",
       "      <td>950.001265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>200.703677</td>\n",
       "      <td>0.503020</td>\n",
       "      <td>-97.884070</td>\n",
       "      <td>-1.048160</td>\n",
       "      <td>230.642983</td>\n",
       "      <td>-119.815810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.751287</td>\n",
       "      <td>0.754335</td>\n",
       "      <td>12.819480</td>\n",
       "      <td>1.796370</td>\n",
       "      <td>953.383755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>203.424740</td>\n",
       "      <td>2.225160</td>\n",
       "      <td>-87.614030</td>\n",
       "      <td>-1.039130</td>\n",
       "      <td>233.358560</td>\n",
       "      <td>-115.008580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.596640</td>\n",
       "      <td>5.464340</td>\n",
       "      <td>26.156030</td>\n",
       "      <td>11.423080</td>\n",
       "      <td>968.239710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            y           x1           x2           x3           x4  \\\n",
       "count    5000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "unique      3          NaN          NaN          NaN          NaN   \n",
       "top     Tesla          NaN          NaN          NaN          NaN   \n",
       "freq     2073          NaN          NaN          NaN          NaN   \n",
       "mean      NaN   199.999115     0.014573   -99.948342    -1.053022   \n",
       "std       NaN     1.014776     0.707570     3.169226     0.006610   \n",
       "min       NaN   196.519800    -2.546980  -112.554330    -1.070990   \n",
       "25%       NaN   199.309460    -0.471633  -102.090328    -1.057280   \n",
       "50%       NaN   199.990365     0.018090  -100.005840    -1.053280   \n",
       "75%       NaN   200.703677     0.503020   -97.884070    -1.048160   \n",
       "max       NaN   203.424740     2.225160   -87.614030    -1.039130   \n",
       "\n",
       "                 x5           x6       x7           x8           x9  \\\n",
       "count   5000.000000  5000.000000     5000  5000.000000  5000.000000   \n",
       "unique          NaN          NaN        5          NaN          NaN   \n",
       "top             NaN          NaN  EBIT/Wh          NaN          NaN   \n",
       "freq            NaN          NaN     1706          NaN          NaN   \n",
       "mean     229.938275  -121.014496      NaN     0.013802    -0.005572   \n",
       "std        1.014779     1.795108      NaN     1.209435     1.238413   \n",
       "min      226.472260  -127.403190      NaN    -4.349350    -5.140990   \n",
       "25%      229.246200  -122.232140      NaN    -0.707843    -0.740918   \n",
       "50%      229.930135  -120.996360      NaN    -0.009350    -0.004245   \n",
       "75%      230.642983  -119.815810      NaN     0.751287     0.754335   \n",
       "max      233.358560  -115.008580      NaN     4.596640     5.464340   \n",
       "\n",
       "                x10          x11          x13  \n",
       "count   5000.000000  5000.000000  5000.000000  \n",
       "unique          NaN          NaN          NaN  \n",
       "top             NaN          NaN          NaN  \n",
       "freq            NaN          NaN          NaN  \n",
       "mean      11.069748    -0.377698   950.021404  \n",
       "std        2.744753     3.356351     4.986109  \n",
       "min        0.672290   -11.232970   932.910080  \n",
       "25%        9.242318    -2.620452   946.660668  \n",
       "50%       11.054340    -0.591760   950.001265  \n",
       "75%       12.819480     1.796370   953.383755  \n",
       "max       26.156030    11.423080   968.239710  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AI', 'EBIT/Wh', 'Q2', 'Q3', 'Q1'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.x7.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tesla', 'SpaceX', 'TwitterX'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 6\n",
    "\n",
    "X = df.drop(columns=['y'])\n",
    "Y = df.y\n",
    "X_train, y_train = shuffle(X, Y, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x8', 'x9', 'x10', 'x11', 'x13'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numerical_features = X.select_dtypes(include=['float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#We encode the categorical features\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#We use a PCA on the numerical features \n",
    "\n",
    "numerical_transformer = Pipeline([\n",
    "    ('pca', PCA(n_components=11)),\n",
    "])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#We proceed to the columns transformation\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting's score : 0.8392\n",
      "K-neighbours's score : 0.5198\n",
      "Decision tree's score : 0.7615999999999999\n",
      "SVM (rbf)'s score : 0.5982000000000001\n",
      "SVM (linear)'s score : 0.5626\n",
      "SVM (polynomial)'s score : 0.5277999999999999\n",
      "Random forest's score : 0.8393999999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost's score : 0.735\n",
      "Bagging's score : 0.8173999999999999\n",
      "MLP's score : 0.6516\n",
      "Ridge Classifier's score : 0.6003999999999999\n",
      "\n",
      " Best classifier : Random forest\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, \\\n",
    "GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifiers = {\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"K-neighbours\": KNeighborsClassifier(),\n",
    "    \"Decision tree\": DecisionTreeClassifier(),\n",
    "    \"SVM (rbf)\": SVC(),\n",
    "    \"SVM (linear)\": SVC(kernel=\"linear\"),\n",
    "    \"SVM (polynomial)\": SVC(kernel=\"poly\"),\n",
    "    \"Random forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Adaboost\": AdaBoostClassifier(),\n",
    "    \"Bagging\": BaggingClassifier(random_state=RANDOM_STATE),\n",
    "    \"MLP\": MLPClassifier(max_iter=5000, hidden_layer_sizes=(13,20,20,10,3)),\n",
    "    \"Ridge Classifier\": RidgeClassifierCV()\n",
    "}\n",
    "\n",
    "best_classifier_name = \"\"\n",
    "best_classifier = None\n",
    "best_score = 0\n",
    "cross_validation = StratifiedKFold(shuffle=True, random_state=RANDOM_STATE, n_splits=10)\n",
    "\n",
    "for classifier_name, classifier in classifiers.items():\n",
    "    \n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', classifier)])\n",
    "    classifier_score = np.average(cross_val_score(pipeline, X_train, y_train, cv=cross_validation))\n",
    "\n",
    "    print(f\"{classifier_name}'s score : {classifier_score}\")\n",
    "    \n",
    "    if classifier_score> best_score:\n",
    "        best_score = classifier_score\n",
    "        best_classifier = pipeline\n",
    "        best_classifier_name = classifier_name\n",
    "\n",
    "print(f\"\\n Best classifier : {best_classifier_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.8423999999999999)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "pipeline = Pipeline([('preprocessor', preprocessor), ('forest', RandomForestClassifier(random_state=RANDOM_STATE))])\n",
    "\n",
    "params = { \n",
    " 'forest__bootstrap': [True, False],\n",
    " 'forest__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    " 'forest__max_features': ['log2', 'sqrt'],\n",
    " 'forest__min_samples_leaf': [1, 2, 4],\n",
    " 'forest__min_samples_split': [2, 5, 10],\n",
    " 'forest__n_estimators': [100, 200, 400, 600, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2400]\n",
    "}\n",
    "\n",
    "#Since we can look for all the parameters, because it would be too long, we use RandomizedSearchCV in order to randomly select 120 parameters combinaisons\n",
    "\n",
    "forest_search = RandomizedSearchCV(pipeline, param_distributions=params, n_iter=120, verbose=1, n_jobs=-1, cv=cross_validation)\n",
    "forest_search.fit(X_train, y_train)\n",
    "forest_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgb\u001b[39m\u001b[38;5;124m'\u001b[39m, GradientBoostingClassifier(random_state\u001b[38;5;241m=\u001b[39mRANDOM_STATE))])\n\u001b[1;32m      2\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgb__n_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m : [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgb__max_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m : [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgb__learning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m : [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m],\n\u001b[1;32m      6\u001b[0m }\n\u001b[0;32m----> 8\u001b[0m gb_grid \u001b[38;5;241m=\u001b[39m \u001b[43mGridSearchCV\u001b[49m(pipeline, param_grid\u001b[38;5;241m=\u001b[39mparams, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39mcross_validation)\n\u001b[1;32m      9\u001b[0m gb_grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     10\u001b[0m gb_grid\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([('preprocessor', preprocessor),('gb', GradientBoostingClassifier(random_state=RANDOM_STATE))])\n",
    "params = {\n",
    "    \"gb__n_estimators\" : [50, 100, 200, 300],\n",
    "    \"gb__max_depth\" : [5, 10, 20, None],\n",
    "    \"gb__learning_rate\" : [0.1, 0.2, 0.01, 0.05],\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(pipeline, param_grid=params, verbose=1, n_jobs=-1, cv=cross_validation)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "gb_grid.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
